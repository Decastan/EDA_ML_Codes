{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"4_imbalanced_dataset.ipynb","provenance":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"ovHz7E7VHqeQ"},"source":["<p><img height=\"45px\" src=\"https://drive.google.com/uc?id=1toxeOL-eCjWBm2tkzaGOQT9LEw77PIi2\"align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n","\n","<h1>Conjuntos de datos desbalanceados</h1>\n","<br>\n","\n","*Tiempo aproximado:* ***1 hora***\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"jiLtZvgMHqeT"},"source":["#**Introducción**\n","\n","Usted trabaja como científico de datos para una empresa de telecomunicaciones, y su objetivo actual es predecir si un cliente abandonará el operador. Para alcanzar el objetivo, Usted cuenta con un *dataset* relacionado con la rotación de clientes. Este conjunto de datos tiene varias variables que describen el nivel de uso de una conexión móvil: duración total de llamadas en minutos, cargos de llamadas, llamadas realizadas durante ciertos períodos del día, detalles de llamadas internacionales y detalles de llamadas a servicio al cliente.\n","<br><br>\n","Este conjunto de datos es muy desbalanceado, y los casos en los que los clientes abandonan son la minoría. Entonces, antes de ajustar un clasificador para analizar el abandono de los clientes, Usted ha decidido corregir el desequilibrio de clases. Para esto, va a aplicar diferentes procesos de balanceo y los comparará para encontrar el mejor método antes de ajustar el modelo. "]},{"cell_type":"markdown","metadata":{"id":"3HGyRV33Hqef"},"source":["# **Adquisición de datos y tratamiento inicial**\n","\n","El conjunto de datos es un archivo CSV que está disponible en: https://raw.githubusercontent.com/lvmeninnovations/datasets/main/crispdm/churn.csv. \n","<br><br>\n","Para iniciar, cargue los datos siguiendo el mismo procedimiento que ha hecho en prácticas anteriores."]},{"cell_type":"code","metadata":{"id":"8RRTccEJnOVg","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1620692209239,"user_tz":300,"elapsed":718,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"a4d96dd0-4363-41c3-e4d9-cfa851903410"},"source":["# Importar la librería pandas\n","import pandas as pd\n","\n","# Leer el conjunto de datos por medio de la URL proporcionada y asignarlo a la variable \"churnData\"\n","path = \"https://raw.githubusercontent.com/lvmeninnovations/datasets/main/crispdm/churn.csv\"\n","datosAbandono = pd.read_csv(path)\n","\n","# Observar los primeros registros del dataset\n","datosAbandono.head()"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>churn</th>\n","      <th>accountlength</th>\n","      <th>internationalplan</th>\n","      <th>voicemailplan</th>\n","      <th>numbervmailmessages</th>\n","      <th>totaldayminutes</th>\n","      <th>totaldaycalls</th>\n","      <th>totaldaycharge</th>\n","      <th>totaleveminutes</th>\n","      <th>totalevecalls</th>\n","      <th>totalevecharge</th>\n","      <th>totalnightminutes</th>\n","      <th>totalnightcalls</th>\n","      <th>totalnightcharge</th>\n","      <th>totalintlminutes</th>\n","      <th>totalintlcalls</th>\n","      <th>totalintlcharge</th>\n","      <th>numbercustomerservicecalls</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>No</td>\n","      <td>128</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>25</td>\n","      <td>265.1</td>\n","      <td>110</td>\n","      <td>45.07</td>\n","      <td>197.4</td>\n","      <td>99</td>\n","      <td>16.78</td>\n","      <td>244.7</td>\n","      <td>91</td>\n","      <td>11.01</td>\n","      <td>10.0</td>\n","      <td>3</td>\n","      <td>2.70</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>No</td>\n","      <td>107</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>26</td>\n","      <td>161.6</td>\n","      <td>123</td>\n","      <td>27.47</td>\n","      <td>195.5</td>\n","      <td>103</td>\n","      <td>16.62</td>\n","      <td>254.4</td>\n","      <td>103</td>\n","      <td>11.45</td>\n","      <td>13.7</td>\n","      <td>3</td>\n","      <td>3.70</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>No</td>\n","      <td>137</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>0</td>\n","      <td>243.4</td>\n","      <td>114</td>\n","      <td>41.38</td>\n","      <td>121.2</td>\n","      <td>110</td>\n","      <td>10.30</td>\n","      <td>162.6</td>\n","      <td>104</td>\n","      <td>7.32</td>\n","      <td>12.2</td>\n","      <td>5</td>\n","      <td>3.29</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>No</td>\n","      <td>84</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>0</td>\n","      <td>299.4</td>\n","      <td>71</td>\n","      <td>50.90</td>\n","      <td>61.9</td>\n","      <td>88</td>\n","      <td>5.26</td>\n","      <td>196.9</td>\n","      <td>89</td>\n","      <td>8.86</td>\n","      <td>6.6</td>\n","      <td>7</td>\n","      <td>1.78</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>No</td>\n","      <td>75</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>0</td>\n","      <td>166.7</td>\n","      <td>113</td>\n","      <td>28.34</td>\n","      <td>148.3</td>\n","      <td>122</td>\n","      <td>12.61</td>\n","      <td>186.9</td>\n","      <td>121</td>\n","      <td>8.41</td>\n","      <td>10.1</td>\n","      <td>3</td>\n","      <td>2.73</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  churn  accountlength  ... totalintlcharge numbercustomerservicecalls\n","0    No            128  ...            2.70                          1\n","1    No            107  ...            3.70                          1\n","2    No            137  ...            3.29                          0\n","3    No             84  ...            1.78                          2\n","4    No             75  ...            2.73                          3\n","\n","[5 rows x 18 columns]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"markdown","metadata":{"id":"J2vG1IA06St4"},"source":["Veamos los tipos de datos que tiene el *dataset*."]},{"cell_type":"code","metadata":{"id":"D7UCqToQ5kYB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690331284,"user_tz":300,"elapsed":621,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"f1f839a0-1f7a-43b7-879c-a73bacca5586"},"source":["datosAbandono.dtypes"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["churn                          object\n","accountlength                   int64\n","internationalplan              object\n","voicemailplan                  object\n","numbervmailmessages             int64\n","totaldayminutes               float64\n","totaldaycalls                   int64\n","totaldaycharge                float64\n","totaleveminutes               float64\n","totalevecalls                   int64\n","totalevecharge                float64\n","totalnightminutes             float64\n","totalnightcalls                 int64\n","totalnightcharge              float64\n","totalintlminutes              float64\n","totalintlcalls                  int64\n","totalintlcharge               float64\n","numbercustomerservicecalls      int64\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"cpUOjHZbzcZW"},"source":["* **Normalización**\n","\n","Como el conjunto de datos contiene valores numéricos, primero debemos normalizar los datos. El propósito de la **normalización** es hacer que todos los atributos numéricos estén en una escala común. Un método efectivo que podemos usar aquí para la función de normalización se llama ```MinMaxScaler()```, que convierte todos los datos numéricos a un rango escalado que podemos determinar. La función ```MinMaxScaler``` está disponible dentro del método de ```preprocessing``` de ```sklearn```:"]},{"cell_type":"code","metadata":{"id":"uA6FMeD8zb0H","executionInfo":{"status":"ok","timestamp":1620690332911,"user_tz":300,"elapsed":445,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}}},"source":["# Método preprocessing de la librería sklearn\n","from sklearn import preprocessing\n","\n","# Obtener un objeto MinMaxScaler para poder normalizar los datos\n","minmaxScaler = preprocessing.MinMaxScaler()\n","\n","# Normalizar cada columna numérica (con el rango -1,1)\n","datosAbandono['alScaled'] = minmaxScaler.fit_transform(datosAbandono['accountlength'].values.reshape(-1,1))\n","datosAbandono['nvmmScaled'] = minmaxScaler.fit_transform(datosAbandono['numbervmailmessages'].values.reshape(-1,1))\n","datosAbandono['tdmScaled'] = minmaxScaler.fit_transform(datosAbandono['totaldayminutes'].values.reshape(-1,1))\n","datosAbandono['tdcScaled'] = minmaxScaler.fit_transform(datosAbandono['totaldaycalls'].values.reshape(-1,1))\n","datosAbandono['tdchScaled'] = minmaxScaler.fit_transform(datosAbandono['totaldaycharge'].values.reshape(-1,1))\n","datosAbandono['temScaled'] = minmaxScaler.fit_transform(datosAbandono['totaleveminutes'].values.reshape(-1,1))\n","datosAbandono['tecScaled'] = minmaxScaler.fit_transform(datosAbandono['totalevecalls'].values.reshape(-1,1))\n","datosAbandono['techScaled'] = minmaxScaler.fit_transform(datosAbandono['totalevecharge'].values.reshape(-1,1))\n","datosAbandono['tnmScaled'] = minmaxScaler.fit_transform(datosAbandono['totalnightminutes'].values.reshape(-1,1))\n","datosAbandono['tncScaled'] = minmaxScaler.fit_transform(datosAbandono['totalnightcalls'].values.reshape(-1,1))\n","datosAbandono['tnchScaled'] = minmaxScaler.fit_transform(datosAbandono['totalnightcharge'].values.reshape(-1,1))\n","datosAbandono['timScaled'] = minmaxScaler.fit_transform(datosAbandono['totalintlminutes'].values.reshape(-1,1))\n","datosAbandono['ticScaled'] = minmaxScaler.fit_transform(datosAbandono['totalintlcalls'].values.reshape(-1,1))\n","datosAbandono['tichScaled'] = minmaxScaler.fit_transform(datosAbandono['totalintlcharge'].values.reshape(-1,1))\n","datosAbandono['ncscScaled'] = minmaxScaler.fit_transform(datosAbandono['numbercustomerservicecalls'].values.reshape(-1,1))"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GIkG7_DW6jus"},"source":["Dado que hemos guardado los atributos numéricos transformados como variables separadas, podemos eliminar los atributos originales:"]},{"cell_type":"code","metadata":{"id":"WQgKOk-Y6qcZ","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1620690334810,"user_tz":300,"elapsed":695,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"d746b947-42bb-46f5-f912-3075d3e4db99"},"source":["# Eliminar las columnas originales\n","datosAbandono.drop(['accountlength','numbervmailmessages',\\\n","                'totaldayminutes','totaldaycalls',\\\n","                'totaldaycharge','totaleveminutes',\\\n","                'totalevecalls','totalevecharge',\\\n","                'totalnightminutes','totalnightcalls',\\\n","                'totalnightcharge','totalintlminutes',\\\n","                'totalintlcalls','totalintlcharge',\\\n","                'numbercustomerservicecalls'],\\\n","               axis=1, inplace=True)\n","\n","# Imprimir los primeros registros del conjunto de datos\n","datosAbandono.head()"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>churn</th>\n","      <th>internationalplan</th>\n","      <th>voicemailplan</th>\n","      <th>alScaled</th>\n","      <th>nvmmScaled</th>\n","      <th>tdmScaled</th>\n","      <th>tdcScaled</th>\n","      <th>tdchScaled</th>\n","      <th>temScaled</th>\n","      <th>tecScaled</th>\n","      <th>techScaled</th>\n","      <th>tnmScaled</th>\n","      <th>tncScaled</th>\n","      <th>tnchScaled</th>\n","      <th>timScaled</th>\n","      <th>ticScaled</th>\n","      <th>tichScaled</th>\n","      <th>ncscScaled</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>No</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>0.524793</td>\n","      <td>0.480769</td>\n","      <td>0.754196</td>\n","      <td>0.666667</td>\n","      <td>0.754183</td>\n","      <td>0.542755</td>\n","      <td>0.582353</td>\n","      <td>0.542866</td>\n","      <td>0.619494</td>\n","      <td>0.520000</td>\n","      <td>0.619584</td>\n","      <td>0.500</td>\n","      <td>0.15</td>\n","      <td>0.500000</td>\n","      <td>0.111111</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>No</td>\n","      <td>no</td>\n","      <td>yes</td>\n","      <td>0.438017</td>\n","      <td>0.500000</td>\n","      <td>0.459744</td>\n","      <td>0.745455</td>\n","      <td>0.459672</td>\n","      <td>0.537531</td>\n","      <td>0.605882</td>\n","      <td>0.537690</td>\n","      <td>0.644051</td>\n","      <td>0.588571</td>\n","      <td>0.644344</td>\n","      <td>0.685</td>\n","      <td>0.15</td>\n","      <td>0.685185</td>\n","      <td>0.111111</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>No</td>\n","      <td>no</td>\n","      <td>no</td>\n","      <td>0.561983</td>\n","      <td>0.000000</td>\n","      <td>0.692461</td>\n","      <td>0.690909</td>\n","      <td>0.692436</td>\n","      <td>0.333242</td>\n","      <td>0.647059</td>\n","      <td>0.333225</td>\n","      <td>0.411646</td>\n","      <td>0.594286</td>\n","      <td>0.411930</td>\n","      <td>0.610</td>\n","      <td>0.25</td>\n","      <td>0.609259</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>No</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>0.342975</td>\n","      <td>0.000000</td>\n","      <td>0.851778</td>\n","      <td>0.430303</td>\n","      <td>0.851740</td>\n","      <td>0.170195</td>\n","      <td>0.517647</td>\n","      <td>0.170171</td>\n","      <td>0.498481</td>\n","      <td>0.508571</td>\n","      <td>0.498593</td>\n","      <td>0.330</td>\n","      <td>0.35</td>\n","      <td>0.329630</td>\n","      <td>0.222222</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>No</td>\n","      <td>yes</td>\n","      <td>no</td>\n","      <td>0.305785</td>\n","      <td>0.000000</td>\n","      <td>0.474253</td>\n","      <td>0.684848</td>\n","      <td>0.474230</td>\n","      <td>0.407754</td>\n","      <td>0.717647</td>\n","      <td>0.407959</td>\n","      <td>0.473165</td>\n","      <td>0.691429</td>\n","      <td>0.473270</td>\n","      <td>0.505</td>\n","      <td>0.15</td>\n","      <td>0.505556</td>\n","      <td>0.333333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  churn internationalplan voicemailplan  ...  ticScaled  tichScaled  ncscScaled\n","0    No                no           yes  ...       0.15    0.500000    0.111111\n","1    No                no           yes  ...       0.15    0.685185    0.111111\n","2    No                no            no  ...       0.25    0.609259    0.000000\n","3    No               yes            no  ...       0.35    0.329630    0.222222\n","4    No               yes            no  ...       0.15    0.505556    0.333333\n","\n","[5 rows x 18 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"PNQKm4CF7Hk1"},"source":["* **Transformar variables nominales a numéricas**\n","\n","Crearemos las variables ficticias para todos los atributos nominales:"]},{"cell_type":"code","metadata":{"id":"5rnqoEEU7Z2N","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1620690345561,"user_tz":300,"elapsed":470,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"4c2d6e89-d84a-4691-c995-3f6c7c208856"},"source":["# Convertir todas las variables categóricas a variables dummy (excepto la clase)\n","datosAbandonoCat = pd.get_dummies(datosAbandono[['internationalplan','voicemailplan']])\n","\n","# Visualizar el dataframe que contiene las variables dummy\n","datosAbandonoCat.head()"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>internationalplan_no</th>\n","      <th>internationalplan_yes</th>\n","      <th>voicemailplan_no</th>\n","      <th>voicemailplan_yes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   internationalplan_no  ...  voicemailplan_yes\n","0                     1  ...                  1\n","1                     1  ...                  1\n","2                     1  ...                  0\n","3                     0  ...                  0\n","4                     0  ...                  0\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"AZZIrYlJfLmD"},"source":["Una vez que se transforman los valores categóricos, deben combinarse con los valores numéricos escalados del *data frame*."]},{"cell_type":"markdown","metadata":{"id":"Rv_ZSGQrbjvZ"},"source":["# **Creación de la versión de entrenamiento/prueba del dataset**\n","\n","Vamos a separar los datos numéricos transformados del conjunto de datos original para luego concatenarlos con las variables categóricas ficticias que creamos en el paso anterior."]},{"cell_type":"code","metadata":{"id":"a8K7mU1Kb-5Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690414953,"user_tz":300,"elapsed":721,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"4275199e-c1fb-47f6-af62-96f103770a09"},"source":["# Separamos los datos numéricos en otro dataframe (denominado churnNum)\n","datosAbandonoNum = datosAbandono[['alScaled','nvmmScaled',\\\n","                      'tdmScaled','tdcScaled',\\\n","                      'tdchScaled','temScaled',\\\n","                      'tecScaled','techScaled',\\\n","                      'tnmScaled','tncScaled',\\\n","                      'tnchScaled','timScaled',\\\n","                      'ticScaled','tichScaled','ncscScaled']]\n","\n","# Vemos el tamaño del dataframe que contiene los datos numéricos\n","datosAbandonoNum.shape"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5000, 15)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"pz3HZED-aOu-"},"source":["En este paso, concatenamos las variables categóricas transformadas y las variables numéricas usando la función ```pd.concat()``` para formar la variable ```X``` (contiene las variables independientes). La etiqueta de la variable de destino se almacena como la variable ```Y``` (variable dependiente o clase)\n","\n"]},{"cell_type":"code","metadata":{"id":"wOA6Akpdf2Fc","colab":{"base_uri":"https://localhost:8080/","height":258},"executionInfo":{"status":"ok","timestamp":1620690416077,"user_tz":300,"elapsed":581,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"dd18e2a3-6384-4c72-c5bd-27b443d8dcdf"},"source":["# Fusión de los dataframe\n","\n","# Preparar las variables X (el parámetro axis=1 indica que la concatenación se hace a lo ancho)\n","X = pd.concat([datosAbandonoCat, datosAbandonoNum], axis=1) \n","print(X.shape)\n","\n","# Preparar la variable Y\n","Y = datosAbandono['churn']\n","print(Y.shape)\n","X.head()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(5000, 19)\n","(5000,)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>internationalplan_no</th>\n","      <th>internationalplan_yes</th>\n","      <th>voicemailplan_no</th>\n","      <th>voicemailplan_yes</th>\n","      <th>alScaled</th>\n","      <th>nvmmScaled</th>\n","      <th>tdmScaled</th>\n","      <th>tdcScaled</th>\n","      <th>tdchScaled</th>\n","      <th>temScaled</th>\n","      <th>tecScaled</th>\n","      <th>techScaled</th>\n","      <th>tnmScaled</th>\n","      <th>tncScaled</th>\n","      <th>tnchScaled</th>\n","      <th>timScaled</th>\n","      <th>ticScaled</th>\n","      <th>tichScaled</th>\n","      <th>ncscScaled</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.524793</td>\n","      <td>0.480769</td>\n","      <td>0.754196</td>\n","      <td>0.666667</td>\n","      <td>0.754183</td>\n","      <td>0.542755</td>\n","      <td>0.582353</td>\n","      <td>0.542866</td>\n","      <td>0.619494</td>\n","      <td>0.520000</td>\n","      <td>0.619584</td>\n","      <td>0.500</td>\n","      <td>0.15</td>\n","      <td>0.500000</td>\n","      <td>0.111111</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.438017</td>\n","      <td>0.500000</td>\n","      <td>0.459744</td>\n","      <td>0.745455</td>\n","      <td>0.459672</td>\n","      <td>0.537531</td>\n","      <td>0.605882</td>\n","      <td>0.537690</td>\n","      <td>0.644051</td>\n","      <td>0.588571</td>\n","      <td>0.644344</td>\n","      <td>0.685</td>\n","      <td>0.15</td>\n","      <td>0.685185</td>\n","      <td>0.111111</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.561983</td>\n","      <td>0.000000</td>\n","      <td>0.692461</td>\n","      <td>0.690909</td>\n","      <td>0.692436</td>\n","      <td>0.333242</td>\n","      <td>0.647059</td>\n","      <td>0.333225</td>\n","      <td>0.411646</td>\n","      <td>0.594286</td>\n","      <td>0.411930</td>\n","      <td>0.610</td>\n","      <td>0.25</td>\n","      <td>0.609259</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.342975</td>\n","      <td>0.000000</td>\n","      <td>0.851778</td>\n","      <td>0.430303</td>\n","      <td>0.851740</td>\n","      <td>0.170195</td>\n","      <td>0.517647</td>\n","      <td>0.170171</td>\n","      <td>0.498481</td>\n","      <td>0.508571</td>\n","      <td>0.498593</td>\n","      <td>0.330</td>\n","      <td>0.35</td>\n","      <td>0.329630</td>\n","      <td>0.222222</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.305785</td>\n","      <td>0.000000</td>\n","      <td>0.474253</td>\n","      <td>0.684848</td>\n","      <td>0.474230</td>\n","      <td>0.407754</td>\n","      <td>0.717647</td>\n","      <td>0.407959</td>\n","      <td>0.473165</td>\n","      <td>0.691429</td>\n","      <td>0.473270</td>\n","      <td>0.505</td>\n","      <td>0.15</td>\n","      <td>0.505556</td>\n","      <td>0.333333</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   internationalplan_no  internationalplan_yes  ...  tichScaled  ncscScaled\n","0                     1                      0  ...    0.500000    0.111111\n","1                     1                      0  ...    0.685185    0.111111\n","2                     1                      0  ...    0.609259    0.000000\n","3                     0                      1  ...    0.329630    0.222222\n","4                     0                      1  ...    0.505556    0.333333\n","\n","[5 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"jFfppMgPgbFN"},"source":["Ahora, necesitaremos la función ```train_test_split()```, por lo que las importaremos desde ```sklearn```. Esta función nos permitirá dividir el *dataset* en un conjunto de datos de entrenamiento y otro de prueba.\n","<br><br>\n","Dividiremos los datos entre datos de entrenamiento y de prueba en una proporción de **70:30** utilizando la variable ```test_size=0.3``` en la función de división. También establecemos un valor para el parámetro ```random_state``` para la reproducibilidad del código:"]},{"cell_type":"code","metadata":{"id":"cnVWrqWygqaf","executionInfo":{"status":"ok","timestamp":1620690418113,"user_tz":300,"elapsed":435,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}}},"source":["# Importar la función train_test_split\n","from sklearn.model_selection import train_test_split\n","\n","# Dividir los datos en conjuntos de entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=123)"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CMMa1vZ2soSz"},"source":["# **Creación de un modelo de clasificación sin realizar balancedo de clases**\n","\n","Antes de aplicar los métodos de balanceo, veamos cómo se comporta un modelo de clasificación (en este caso de Regresión Logística) al ser entrenado con los datos desbalanceados.\n","<br><br>\n","Entrene el algoritmo de Regresión Logística usando la función ```.fit``` en los datos de entrenamiento."]},{"cell_type":"code","metadata":{"id":"3r6ElE52sqwd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690419786,"user_tz":300,"elapsed":459,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"0bfad92e-35cb-4d46-ceae-db4b9999d51e"},"source":["from sklearn.linear_model import LogisticRegression\n","\n","# Definir la función LogisticRegression y entrenar con los datos de entrenamiento\n","modelo = LogisticRegression()\n","modelo.fit(X_train, y_train)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"GvO1u17vw6cD"},"source":["Ahora que el modelo se ha creado, realizaremos predicciones con el conjunto de prueba y generaremos las métricas de rendimiento. Veamos primero la precisión del modelo (*accuracy*) y la matriz de confusión."]},{"cell_type":"code","metadata":{"id":"_WQsxDPeyacb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690421517,"user_tz":300,"elapsed":503,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"a65896a7-2bed-4bbd-e56a-ba6689a8dc97"},"source":["# Importar la función confusion_matrix de sklearn\n","from sklearn.metrics import confusion_matrix\n","\n","# Hacemos predicciones con el conjunto de prueba\n","predicciones = modelo.predict(X_test)\n","\n","# Obtenemos la matriz de confusión a partir de los resultados obtenidos\n","confusionMatrix = confusion_matrix(y_test, predicciones)\n","print(\"---MATRIZ DE CONFUSIÓN---\")\n","print(confusionMatrix)\n","print(\"-------------------------\")\n","\n","# Obtenemos la precisión del modelo\n","accuracy = modelo.score(X_test, y_test)\n","print('La precisión del modelo de Regresión Logística con en el conjunto de prueba es:', accuracy)\n"],"execution_count":23,"outputs":[{"output_type":"stream","text":["---MATRIZ DE CONFUSIÓN---\n","[[1259   24]\n"," [ 179   38]]\n","-------------------------\n","La precisión del modelo de Regresión Logística con en el conjunto de prueba es: 0.8646666666666667\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dYkUxQnidf1q"},"source":["## Ejercicio 1\n","\n","```sklearn``` le permite utilizar la función ```classification_report``` para obtener un reporte más completo del rendimiento del modelo de clasificacion. **Importe dicha función y obtenga el reporte de su modelo**. El uso de esta función es similar al procedimiento que se hizo con la función ```confusion_matrix``` y hacen parte del mismo paquete de ```sklearn```."]},{"cell_type":"code","metadata":{"id":"XsPG4nFTd71A","executionInfo":{"status":"ok","timestamp":1620690431421,"user_tz":300,"elapsed":484,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}}},"source":["# Escriba su código a continuación y presione Shift + Enter para ejecutar\n"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"geME97Iwd-aK"},"source":["**SOLUCIÓN DEL EJERCICIO:**"]},{"cell_type":"markdown","metadata":{"id":"C23usC5oeCCT"},"source":["Haga doble clic **aquí** para ver la solución del Ejercicio 1. \n","\n","<!-- La respuesta es la siguiente:\n","\n","# Importar la función classification_report de sklearn\n","from sklearn.metrics import classification_report\n","print(\"---REPORTE DE LA CLASIFICACIÓN---\")\n","reporte = classification_report(y_test, predicciones)\n","print(reporte)\n","\n","-->"]},{"cell_type":"markdown","metadata":{"id":"5FX6zB_h3sCi"},"source":["Como se puede observar, aunque la precisión general (*accuracy*) del modelo es buena, la matriz de confusión nos indica que esta medida es engañosa, pues es evidente que no se ha obtenido un buen resultado para la clase minoritaria. El reporte que obtuvo en el ejercicio anterior también le demuestra el mal comportamiento (en este caso, vea especialmente el valor de *Recall*). El desbalanceo de clase es una de las principales razones detrás de las malas métricas que hemos obtenido con el clasificador de Regresión Logística."]},{"cell_type":"markdown","metadata":{"id":"bbNeRUas6AaT"},"source":["# **Estrategias para lidiar con el desbalanceo de clases**\n","\n","En muchas circunstancias, recopilar más datos, especialmente de las clases minoritarias, puede ser un desafío. En tales circunstancias, debemos adoptar diferentes estrategias para trabajar con nuestras limitaciones y esforzarnos por balancear nuestro conjunto de datos."]},{"cell_type":"markdown","metadata":{"id":"bdV2pzxmHqfG"},"source":["## *Método de Remuestreo (Submuestreo o Undersampling)*\n","\n","La idea detrás del remuestreo es elegir al azar muestras de la clase mayoritaria para hacer que el conjunto de datos final sea más equilibrado. Como resultado, la clase minoritaria tendrá el mismo número de instancias originales, mientras que la clase mayoritaria estará submuestreada. El remuestreo de este tipo se denomina **submuestreo aleatorio** porque estamos submuestreando la clase mayoritaria.\n","<br><br>\n","Antes de continuar con el proceso de remuestreo, concatenamos los conjuntos de datos ```X_train``` y ```y_train``` en un solo conjunto de datos (esto es el conjunto de datos de entrenamiento con sus respectivas etiquetas). Esto se hace para facilitar el proceso de remuestreo en los pasos siguientes. "]},{"cell_type":"code","metadata":{"id":"_ut6YjmSDehm","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1620694729080,"user_tz":300,"elapsed":593,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"cdca65fe-77f9-4792-9818-bb37c58fc7cd"},"source":["# Concatenar train_x train_y para facilitar las operaciones posteriores\n","trainData = pd.concat([X_train,y_train],axis=1)\n","trainData.head()"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>internationalplan_no</th>\n","      <th>internationalplan_yes</th>\n","      <th>voicemailplan_no</th>\n","      <th>voicemailplan_yes</th>\n","      <th>alScaled</th>\n","      <th>nvmmScaled</th>\n","      <th>tdmScaled</th>\n","      <th>tdcScaled</th>\n","      <th>tdchScaled</th>\n","      <th>temScaled</th>\n","      <th>tecScaled</th>\n","      <th>techScaled</th>\n","      <th>tnmScaled</th>\n","      <th>tncScaled</th>\n","      <th>tnchScaled</th>\n","      <th>timScaled</th>\n","      <th>ticScaled</th>\n","      <th>tichScaled</th>\n","      <th>ncscScaled</th>\n","      <th>churn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4036</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.256198</td>\n","      <td>0.500000</td>\n","      <td>0.609388</td>\n","      <td>0.484848</td>\n","      <td>0.609270</td>\n","      <td>0.695628</td>\n","      <td>0.894118</td>\n","      <td>0.695891</td>\n","      <td>0.395949</td>\n","      <td>0.622857</td>\n","      <td>0.396173</td>\n","      <td>0.515</td>\n","      <td>0.10</td>\n","      <td>0.514815</td>\n","      <td>0.222222</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2883</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.504132</td>\n","      <td>0.000000</td>\n","      <td>0.595733</td>\n","      <td>0.296970</td>\n","      <td>0.595716</td>\n","      <td>0.652736</td>\n","      <td>0.688235</td>\n","      <td>0.652863</td>\n","      <td>0.605570</td>\n","      <td>0.560000</td>\n","      <td>0.605515</td>\n","      <td>0.490</td>\n","      <td>0.55</td>\n","      <td>0.490741</td>\n","      <td>0.111111</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4162</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.012397</td>\n","      <td>0.000000</td>\n","      <td>0.482788</td>\n","      <td>0.581818</td>\n","      <td>0.482764</td>\n","      <td>0.362387</td>\n","      <td>0.552941</td>\n","      <td>0.362342</td>\n","      <td>0.620506</td>\n","      <td>0.491429</td>\n","      <td>0.620709</td>\n","      <td>0.710</td>\n","      <td>0.20</td>\n","      <td>0.709259</td>\n","      <td>0.000000</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4640</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.450413</td>\n","      <td>0.000000</td>\n","      <td>0.714936</td>\n","      <td>0.551515</td>\n","      <td>0.714859</td>\n","      <td>0.569700</td>\n","      <td>0.558824</td>\n","      <td>0.569719</td>\n","      <td>0.630380</td>\n","      <td>0.400000</td>\n","      <td>0.630838</td>\n","      <td>0.645</td>\n","      <td>0.10</td>\n","      <td>0.644444</td>\n","      <td>0.111111</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2430</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.491736</td>\n","      <td>0.769231</td>\n","      <td>0.364438</td>\n","      <td>0.600000</td>\n","      <td>0.364458</td>\n","      <td>0.681056</td>\n","      <td>0.458824</td>\n","      <td>0.681009</td>\n","      <td>0.505570</td>\n","      <td>0.691429</td>\n","      <td>0.505909</td>\n","      <td>0.780</td>\n","      <td>0.15</td>\n","      <td>0.779630</td>\n","      <td>0.000000</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      internationalplan_no  internationalplan_yes  ...  ncscScaled  churn\n","4036                     1                      0  ...    0.222222     No\n","2883                     1                      0  ...    0.111111     No\n","4162                     0                      1  ...    0.000000    Yes\n","4640                     1                      0  ...    0.111111    Yes\n","2430                     1                      0  ...    0.000000     No\n","\n","[5 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"PR5TK8x7DoBy"},"source":["Para hacer el proceso de submuestreo, primero separaremos las instancias de la clase minoritaria y de la clase mayoritaria. Esto es necesario porque tenemos que muestrear por separado a la clase mayoritaria para crear un conjunto de datos equilibrado."]},{"cell_type":"markdown","metadata":{"id":"BC4O66joC5HU"},"source":["* **Obtener las instancias de la clase minoritaria**\n","\n","Para separar la clase minoritaria, tenemos que identificar los índices del conjunto de datos donde las instancias tienen la etiqueta 'yes' en su clase. \n","<br><br>\n","Los índices se identifican mediante la función ```.index()```:\n"]},{"cell_type":"code","metadata":{"id":"J_Qj4cTnErBn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690447183,"user_tz":300,"elapsed":599,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"a1ee8504-63c2-41d2-f280-f940830842f0"},"source":["# Encontrar los índices de las instancias donde la etiqueta/clase (columna churn) es 'yes'\n","minIndices = trainData[trainData['churn']=='Yes'].index\n","\n","# Imprimir el número de instancias con la etiqueta 'yes'\n","print(len(minIndices))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["490\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yPGMLZf0DC7K"},"source":["Una vez que se identifican los índices de la clase minoritaria, se separan del conjunto de datos principal mediante la función ```.loc()``` y se almacenan en una nueva variable para la clase minoritaria."]},{"cell_type":"code","metadata":{"id":"jIje-asucOBr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690449068,"user_tz":300,"elapsed":577,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"28a54ce7-0b8f-4099-f392-4069f4069a08"},"source":["# Obtener las instancias que representan la clase minoritara\n","minData = trainData.loc[minIndices]\n","\n","# Imprimir el tamaño (el número de filas debe coincidir con el tamaño que arrojó código anterior)\n","print(minData.shape)"],"execution_count":28,"outputs":[{"output_type":"stream","text":["(490, 20)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LCpIywpadlJz"},"source":["* **Obtener las instancias de la clase mayoritaria**\n","\n","Para obtener la instancias de la clase mayoritaria, realice el Ejercicio 2"]},{"cell_type":"markdown","metadata":{"id":"l9TIk294eKTO"},"source":["### Ejercicio 2\n","\n","**Con base en el proceso anterior, separe la clase mayoritaria del conjunto de datos principal y almacene el resultado en la variable ```majData```.**"]},{"cell_type":"code","metadata":{"id":"84AC5fAde-Jr","executionInfo":{"status":"ok","timestamp":1620690482116,"user_tz":300,"elapsed":437,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}}},"source":["# Escriba su código a continuación y presione Shift + Enter para ejecutar\n","# Encontrar los índices de las instancias donde la etiqueta/clase (columna churn) es 'no'\n","majIndices = trainData[trainData['churn']=='No'].index\n","\n","# Obtener las instancias que representan la clase minoritara\n","majData = trainData.loc[majIndices]"],"execution_count":31,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fwm6Cp7GfCEj"},"source":["**SOLUCIÓN DEL EJERCICIO:**"]},{"cell_type":"markdown","metadata":{"id":"8phMURemfE9k"},"source":["Haga doble clic **aquí** para ver la solución del Ejercicio 2. \n","\n","<!-- La respuesta es la siguiente:\n","\n","\n","\n","-->"]},{"cell_type":"markdown","metadata":{"id":"_g2Ssr4ufqYU"},"source":["* **Muestreo de la clase mayoritaria**\n","\n","Tome una muestra aleatoria de la clase mayoritaria con una longitud igual a la de la clase minoritaria, para poder equilibrar el conjunto de datos."]},{"cell_type":"code","metadata":{"id":"us4Nv42HgGt3","colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"status":"ok","timestamp":1620690484863,"user_tz":300,"elapsed":422,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"7043e459-d5d8-47f4-bd31-f99942c18b95"},"source":["# Tomar aleatoriamente instancias de la clase mayoritaria\n","# el número de instancias será igual al número de instancias de la clase minoritaria = len(minIndices)\n","majMuestra = majData.sample(n=len(minIndices), random_state = 123)\n","\n","# Imprimir el tamaño de la muestra\n","print(majMuestra.shape)\n","\n","# Imprimir los primeros registros dela muestra\n","majMuestra.head()"],"execution_count":32,"outputs":[{"output_type":"stream","text":["(490, 20)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>internationalplan_no</th>\n","      <th>internationalplan_yes</th>\n","      <th>voicemailplan_no</th>\n","      <th>voicemailplan_yes</th>\n","      <th>alScaled</th>\n","      <th>nvmmScaled</th>\n","      <th>tdmScaled</th>\n","      <th>tdcScaled</th>\n","      <th>tdchScaled</th>\n","      <th>temScaled</th>\n","      <th>tecScaled</th>\n","      <th>techScaled</th>\n","      <th>tnmScaled</th>\n","      <th>tncScaled</th>\n","      <th>tnchScaled</th>\n","      <th>timScaled</th>\n","      <th>ticScaled</th>\n","      <th>tichScaled</th>\n","      <th>ncscScaled</th>\n","      <th>churn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1807</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.450413</td>\n","      <td>0.000000</td>\n","      <td>0.557895</td>\n","      <td>0.624242</td>\n","      <td>0.557898</td>\n","      <td>0.549079</td>\n","      <td>0.723529</td>\n","      <td>0.549013</td>\n","      <td>0.344051</td>\n","      <td>0.405714</td>\n","      <td>0.344401</td>\n","      <td>0.645</td>\n","      <td>0.05</td>\n","      <td>0.644444</td>\n","      <td>0.333333</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4578</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.475207</td>\n","      <td>0.000000</td>\n","      <td>0.244097</td>\n","      <td>0.533333</td>\n","      <td>0.244143</td>\n","      <td>0.318394</td>\n","      <td>0.658824</td>\n","      <td>0.318344</td>\n","      <td>0.495949</td>\n","      <td>0.520000</td>\n","      <td>0.496342</td>\n","      <td>0.550</td>\n","      <td>0.10</td>\n","      <td>0.550000</td>\n","      <td>0.111111</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>355</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.123967</td>\n","      <td>0.000000</td>\n","      <td>0.472546</td>\n","      <td>0.636364</td>\n","      <td>0.472557</td>\n","      <td>0.218037</td>\n","      <td>0.547059</td>\n","      <td>0.218052</td>\n","      <td>0.541013</td>\n","      <td>0.560000</td>\n","      <td>0.541362</td>\n","      <td>0.635</td>\n","      <td>0.10</td>\n","      <td>0.635185</td>\n","      <td>0.111111</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.454545</td>\n","      <td>0.000000</td>\n","      <td>0.314083</td>\n","      <td>0.624242</td>\n","      <td>0.314090</td>\n","      <td>0.377509</td>\n","      <td>0.600000</td>\n","      <td>0.377548</td>\n","      <td>0.480000</td>\n","      <td>0.600000</td>\n","      <td>0.480023</td>\n","      <td>0.385</td>\n","      <td>0.30</td>\n","      <td>0.385185</td>\n","      <td>0.222222</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>1541</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.194215</td>\n","      <td>0.692308</td>\n","      <td>0.656899</td>\n","      <td>0.557576</td>\n","      <td>0.656794</td>\n","      <td>0.460819</td>\n","      <td>0.711765</td>\n","      <td>0.461016</td>\n","      <td>0.683544</td>\n","      <td>0.497143</td>\n","      <td>0.683737</td>\n","      <td>0.380</td>\n","      <td>0.20</td>\n","      <td>0.379630</td>\n","      <td>0.333333</td>\n","      <td>No</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      internationalplan_no  internationalplan_yes  ...  ncscScaled  churn\n","1807                     1                      0  ...    0.333333     No\n","4578                     1                      0  ...    0.111111     No\n","355                      1                      0  ...    0.111111     No\n","23                       1                      0  ...    0.222222     No\n","1541                     1                      0  ...    0.333333     No\n","\n","[5 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"ohQL9jrRhY34"},"source":["* **Prepare el nuevo dataset**\n","\n","Ahora podemos concatenar estos conjuntos de datos individuales (conjunto de la clase minoritaria y muestreo de la clase mayoritaria) usando la función ```pd.concat()```. En este caso, estamos concatenando verticalmente los datos, por lo tanto, se usa el parámetro ```axis = 0```."]},{"cell_type":"code","metadata":{"id":"K5OKl9Lij3nx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690487924,"user_tz":300,"elapsed":423,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"e5e4ffef-efa2-4da7-ff63-bd01d9d11402"},"source":["# Concatenar ambos datasets\n","balancedData = pd.concat([minData,majMuestra],axis = 0)\n","print('Tamaño del conjunto de datos balanceado',balancedData.shape)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Tamaño del conjunto de datos balanceado (980, 20)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IL9fF4yXlCCl"},"source":["Ahora, baraje el nuevo conjunto de datos para que tanto las clases minoritarias como las mayoritarias se distribuyan uniformemente. Para esto, utilice función ```shuffle()```:"]},{"cell_type":"code","metadata":{"id":"Zprt-UMFlBhY","colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"status":"ok","timestamp":1620690489786,"user_tz":300,"elapsed":500,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"fd2a26e7-0f42-474f-f3bc-21eaf786c96f"},"source":["# Importar la función shuffle\n","from sklearn.utils import shuffle\n","\n","# Barajar el dataset\n","balancedData = shuffle(balancedData)\n","# Imprimir los primeros registros del dataset\n","balancedData.head()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>internationalplan_no</th>\n","      <th>internationalplan_yes</th>\n","      <th>voicemailplan_no</th>\n","      <th>voicemailplan_yes</th>\n","      <th>alScaled</th>\n","      <th>nvmmScaled</th>\n","      <th>tdmScaled</th>\n","      <th>tdcScaled</th>\n","      <th>tdchScaled</th>\n","      <th>temScaled</th>\n","      <th>tecScaled</th>\n","      <th>techScaled</th>\n","      <th>tnmScaled</th>\n","      <th>tncScaled</th>\n","      <th>tnchScaled</th>\n","      <th>timScaled</th>\n","      <th>ticScaled</th>\n","      <th>tichScaled</th>\n","      <th>ncscScaled</th>\n","      <th>churn</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4120</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.128099</td>\n","      <td>0.000000</td>\n","      <td>0.755334</td>\n","      <td>0.454545</td>\n","      <td>0.755355</td>\n","      <td>0.329117</td>\n","      <td>0.452941</td>\n","      <td>0.329020</td>\n","      <td>0.430127</td>\n","      <td>0.731429</td>\n","      <td>0.430501</td>\n","      <td>0.740</td>\n","      <td>0.30</td>\n","      <td>0.740741</td>\n","      <td>0.222222</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2862</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.516529</td>\n","      <td>0.461538</td>\n","      <td>0.167568</td>\n","      <td>0.757576</td>\n","      <td>0.167503</td>\n","      <td>0.839978</td>\n","      <td>0.529412</td>\n","      <td>0.840181</td>\n","      <td>0.402278</td>\n","      <td>0.417143</td>\n","      <td>0.402364</td>\n","      <td>0.605</td>\n","      <td>0.30</td>\n","      <td>0.605556</td>\n","      <td>0.000000</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>4576</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.537190</td>\n","      <td>0.000000</td>\n","      <td>0.730014</td>\n","      <td>0.581818</td>\n","      <td>0.729920</td>\n","      <td>0.619192</td>\n","      <td>0.664706</td>\n","      <td>0.619217</td>\n","      <td>0.481519</td>\n","      <td>0.520000</td>\n","      <td>0.481711</td>\n","      <td>0.555</td>\n","      <td>0.15</td>\n","      <td>0.555556</td>\n","      <td>0.111111</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>2203</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0.396694</td>\n","      <td>0.000000</td>\n","      <td>0.412518</td>\n","      <td>0.624242</td>\n","      <td>0.412483</td>\n","      <td>0.809183</td>\n","      <td>0.547059</td>\n","      <td>0.809447</td>\n","      <td>0.607089</td>\n","      <td>0.685714</td>\n","      <td>0.607203</td>\n","      <td>0.550</td>\n","      <td>0.10</td>\n","      <td>0.550000</td>\n","      <td>0.444444</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>3851</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0.731405</td>\n","      <td>0.615385</td>\n","      <td>0.423044</td>\n","      <td>0.575758</td>\n","      <td>0.423025</td>\n","      <td>0.546054</td>\n","      <td>0.323529</td>\n","      <td>0.546102</td>\n","      <td>0.473418</td>\n","      <td>0.645714</td>\n","      <td>0.473270</td>\n","      <td>0.520</td>\n","      <td>0.35</td>\n","      <td>0.520370</td>\n","      <td>0.666667</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      internationalplan_no  internationalplan_yes  ...  ncscScaled  churn\n","4120                     0                      1  ...    0.222222    Yes\n","2862                     1                      0  ...    0.000000     No\n","4576                     1                      0  ...    0.111111    Yes\n","2203                     0                      1  ...    0.444444    Yes\n","3851                     1                      0  ...    0.666667    Yes\n","\n","[5 rows x 20 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"Sk6FrO1umlaj"},"source":["Ahora, separe el conjunto de datos barajado en variables independientes, ```X_train_sub```, y variables dependientes, ```y_train_sub```. La separación de las variables independientes la podemos realizar utilizando la función ```.iloc()``` de pandas. (Utilizamos el sufijo ```_sub``` en los nombres de las variables para indicar que representan el conjunto de datos de entrenamiento obtenido por medio de un proceso de submuestreo)."]},{"cell_type":"code","metadata":{"id":"kRepoB27nRt_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690491996,"user_tz":300,"elapsed":451,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"84643aa0-b534-441c-c818-cf282bc447ac"},"source":["# Crear los nuevos X_train y y_train\n","\n","# Crear las nuevas variables independientes\n","X_train_sub = balancedData.iloc[:,0:19]\n","print('Tamaño del nuevo conjunto de entrenamiento (variables independientes)', X_train_sub.shape)\n","\n","# Crear la nueva variable dependiente y_train\n","y_train_sub = balancedData['churn']\n","print('Tamaño del nuevo conjunto de entrenamiento (varible dependiente)',y_train_sub.shape)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Tamaño del nuevo conjunto de entrenamiento (variables independientes) (980, 19)\n","Tamaño del nuevo conjunto de entrenamiento (varible dependiente) (980,)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"m4XOUJqwqgj6"},"source":["Nuestro nuevo dataset de entrenamiento está listo para ajustar un nuevo modelo de Regresión Logística (para este caso particular) y comparar los resultados con el comportamiento del modelo construido sin balancear los datos. Pero antes de realizar esta evaluación, realicemos otros procedimientos de balanceo de datos.\n"]},{"cell_type":"markdown","metadata":{"id":"Q4ui9NvI-2qP"},"source":["## *Método de sobremuestreo (SMOTE)*\n","\n","Generaremos muestras sintéticas de la clase minoritaria utilizando el algoritmo **SMOTE** y luego equilibraremos el conjunto de datos. \n","<br><br>\n","* **Importar las librerías necesarias:**\n","\n","Las librerías necesarias para sobremuestrear el conjunto de entrenamiento son ```smote_variants``` y ```numpy```.\n","\n","*NOTA: debemos instalar la librería ```smote_variants``` antes de importarla.*"]},{"cell_type":"code","metadata":{"id":"3eOq0cn3wOcQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690502955,"user_tz":300,"elapsed":7965,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"b1b0b447-010b-44d8-b824-bfba8c9a0b95"},"source":["!pip install smote-variants\t\t\n","\n","import smote_variants as sv\n","import numpy as np"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Collecting smote-variants\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/be/15b4db362d53ded5960da7d439455d2efa4d99f85626145c4bb415fde153/smote_variants-0.4.0-py3-none-any.whl (134kB)\n","\u001b[K     |████████████████████████████████| 143kB 3.8MB/s \n","\u001b[?25hRequirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from smote-variants) (2019.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from smote-variants) (1.0.1)\n","Collecting minisom\n","  Downloading https://files.pythonhosted.org/packages/88/c9/7ef2caebca23a1f1803a057c3df1aef219e230acc4fa824c0944432b6b7a/MiniSom-2.2.9.tar.gz\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from smote-variants) (0.22.2.post1)\n","Collecting statistics\n","  Downloading https://files.pythonhosted.org/packages/bb/3a/ae99a15e65636559d936dd2159d75af1619491e8cb770859fbc8aa62cef6/statistics-1.0.3.5.tar.gz\n","Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from smote-variants) (2.4.3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from smote-variants) (1.1.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from smote-variants) (1.4.1)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from smote-variants) (2.4.1)\n","Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from smote-variants) (1.19.5)\n","Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl->smote-variants) (2021.2.0)\n","Requirement already satisfied: docutils>=0.3 in /usr/local/lib/python3.7/dist-packages (from statistics->smote-variants) (0.17)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->smote-variants) (2.10.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->smote-variants) (3.13)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->smote-variants) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->smote-variants) (2.8.1)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (2.4.1)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (0.2.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (1.6.3)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (0.36.2)\n","Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (1.15.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (3.7.4.3)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (0.3.3)\n","Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (1.32.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (1.1.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (1.12)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (3.3.0)\n","Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (2.4.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (3.12.4)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (1.1.2)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (1.12.1)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->smote-variants) (0.12.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->smote-variants) (1.8.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->smote-variants) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->smote-variants) (56.1.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->smote-variants) (2.23.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->smote-variants) (0.4.4)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->smote-variants) (1.28.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow->smote-variants) (3.3.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->smote-variants) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->smote-variants) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->smote-variants) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->smote-variants) (2.10)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->smote-variants) (1.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->smote-variants) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->smote-variants) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->smote-variants) (4.2.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->smote-variants) (3.10.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->smote-variants) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow->smote-variants) (0.4.8)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow->smote-variants) (3.4.1)\n","Building wheels for collected packages: minisom, statistics\n","  Building wheel for minisom (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for minisom: filename=MiniSom-2.2.9-cp37-none-any.whl size=8603 sha256=214dc41ca3b2eca0ecbd939832258f6b533b0fcc46811de08992f7cf60632cbe\n","  Stored in directory: /root/.cache/pip/wheels/de/a0/08/5234d6b02b29c561f62b6c985e2eb7d480fb0b92359a8c74e4\n","  Building wheel for statistics (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for statistics: filename=statistics-1.0.3.5-cp37-none-any.whl size=7454 sha256=352b94eb1bc6e1f101969b060c18288769ebf3943f3ab35ee99701034a2df484\n","  Stored in directory: /root/.cache/pip/wheels/75/55/90/73aa7662bfb4565b567618547a275f01372a678ca92ecd64f3\n","Successfully built minisom statistics\n","Installing collected packages: minisom, statistics, smote-variants\n","Successfully installed minisom-2.2.9 smote-variants-0.4.0 statistics-1.0.3.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jTc6csWA2d4Z"},"source":["* **Realizar el sobremuestreo de la clase minoritaria**\n","\n","Ahora, cree una instancia de la librería SMOTE en una variable llamada ```oversampler``` usando la función ```sv.SMOTE()```. Esta es una forma común de instanciar cualquiera de las variantes de SMOTE ```smote_variants```.\n","<br><br>\n","*NOTA: aquí puede ver la documentación de todas las variantes de SMOTE disponibles en la librería: https://smote-variants.readthedocs.io/en/latest/oversamplers.html*"]},{"cell_type":"code","metadata":{"id":"HAldr0qi1qps","executionInfo":{"status":"ok","timestamp":1620690502956,"user_tz":300,"elapsed":3983,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}}},"source":["# Instanciando la clase SMOTE \n","oversampler= sv.SMOTE()"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eHLvEJg-1qXZ"},"source":["Utilice la función ```.sample()``` de ```oversampler``` para hacer el proceso de sobremuestreo. Tanto las variables ```X``` como las ```y``` se deben convertir en matrices numpy antes de aplicar la función ```.sample()```:"]},{"cell_type":"code","metadata":{"id":"oNppydnj7rxH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690502957,"user_tz":300,"elapsed":2229,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"6a22cf28-e455-448e-da34-f064b9fe9139"},"source":["# Crear un nuevo conjunto de datos de entrenamiento\n","X_train_smote, y_train_smote = oversampler.sample(np.array(X_train), np.array(y_train))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["2021-05-10 23:48:22,603:INFO:SMOTE: Running sampling via ('SMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"X8c0oPwV9DuC"},"source":["* **Observar el dataset obtenido**\n","\n","Ahora, imprima loa tamaños de las nuevas variables ```X``` y ```y```, y el conteo de las clases. Observará que el tamaño del conjunto de datos general ha aumentado. Este aumento de tamaño se atribuye al hecho de que la clase minoritaria ha sido sobremuestreada de 490 a 3010:"]},{"cell_type":"code","metadata":{"id":"8oiBKH9e9Vjb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690505227,"user_tz":300,"elapsed":505,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"9db7ba03-e4cf-4f81-ae7e-8c95ddab386a"},"source":["# Tamaño después de hacer sobremuestreo\n","print('Después de hacer sobremuestreo, el tamaño de train_X:', X_train_smote.shape)\n","print('Después de hacer sobremuestreo, el tamaño de train_y:', y_train_smote.shape)\n","print(\"Después de hacer sobremuestreo, conteo de la etiqueta 'Yes':\", sum(y_train_smote=='Yes'))\n","print(\"Después de hacer sobremuestreo, conteo de la etiqueta 'no':\", sum(y_train_smote=='No'))"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Después de hacer sobremuestreo, el tamaño de train_X: (6020, 19)\n","Después de hacer sobremuestreo, el tamaño de train_y: (6020,)\n","Después de hacer sobremuestreo, conteo de la etiqueta 'Yes': 3010\n","Después de hacer sobremuestreo, conteo de la etiqueta 'no': 3010\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"InDZDtuPacrI"},"source":["### Ejercicio 3\n","\n","**Siguiendo los mismos pasos que con SMOTE, realice un proceso de sobremuestreo implementando MSMOTE.** Asígne a las variables ```X_train_msmote, y_train_msmote``` el conjunto de datos de entrenamiento resultante"]},{"cell_type":"code","metadata":{"id":"jbqkxIVCbP6H","executionInfo":{"status":"ok","timestamp":1620690507689,"user_tz":300,"elapsed":425,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}}},"source":["# Escriba su código a continuación y presione Shift + Enter para ejecutar\n"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWJz1zn5bWnq"},"source":["**SOLUCIÓN DEL EJERCICIO:**"]},{"cell_type":"markdown","metadata":{"id":"9_7KolnjbXst"},"source":["Haga doble clic **aquí** para ver la solución del Ejercicio 3. \n","\n","<!-- La respuesta es la siguiente:\n","\n","\n","\n","-->"]},{"cell_type":"markdown","metadata":{"id":"JaVM1eCTr8Jx"},"source":["# **Comparación**\n","\n","Hemos obtenido tres nuevas versiones del conjunto de entrenamiento. Vamos a crear un modelo de clasificación (de Regresión Logística para este caso particular) para cada una de ellas. De esta manera podremos comparar los resultados y elegir el método de balanceo más conveniente para nuestro caso particular.\n"]},{"cell_type":"code","metadata":{"id":"LZwTFBVddBhw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690534441,"user_tz":300,"elapsed":1042,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"a0b565d5-9cea-4750-cb3f-8dfdde27901a"},"source":["\n","# Instanciando la clase MSMOTE \n","oversampler= sv.MSMOTE()\n","\n","# Crear un nuevo conjunto de datos de entrenamiento\n","X_train_msmote, y_train_msmote = oversampler.sample(np.array(X_train), np.array(y_train))\n","\n","# Tamaño después de hacer sobremuestreo\n","print('Después de hacer sobremuestreo, el tamaño de train_X:', X_train_msmote.shape)\n","print(\"Después de hacer sobremuestreo, conteo de la etiqueta 'Yes':\", sum(y_train_msmote=='Yes'))\n","print(\"Después de hacer sobremuestreo, conteo de la etiqueta 'no':\", sum(y_train_msmote=='No'))\n","# Creación y entrenamiento del modelo con base en el resultado de submuestreo\n","modelo1 = LogisticRegression()\n","modelo1.fit(X_train_sub, y_train_sub)\n","\n","# Creación y entrenamiento del modelo con base en el resultado de sobremuestreo con SMOTE\n","modelo2 = LogisticRegression()\n","modelo2.fit(X_train_smote, y_train_smote)\n","\n","# Creación y entrenamiento del modelo con base en el resultado de sobremuestreo con MSMOTE\n","modelo3 = LogisticRegression()\n","modelo3.fit(X_train_msmote, y_train_msmote)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["2021-05-10 23:48:53,585:INFO:MSMOTE: Running sampling via ('MSMOTE', \"{'proportion': 1.0, 'n_neighbors': 5, 'n_jobs': 1, 'random_state': None}\")\n"],"name":"stderr"},{"output_type":"stream","text":["Después de hacer sobremuestreo, el tamaño de train_X: (6020, 19)\n","Después de hacer sobremuestreo, conteo de la etiqueta 'Yes': 3010\n","Después de hacer sobremuestreo, conteo de la etiqueta 'no': 3010\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n","                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n","                   multi_class='auto', n_jobs=None, penalty='l2',\n","                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n","                   warm_start=False)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"9snRz8M2dAbP"},"source":["Ahora, necesitamos hacer predicciones con el conjunto de datos de prueba ```X_test```, con cada uno de los modelos:"]},{"cell_type":"code","metadata":{"id":"Hgkb9jlue_T5","executionInfo":{"status":"ok","timestamp":1620690552913,"user_tz":300,"elapsed":476,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}}},"source":["# Predicción utilizando SUBMUESTREO\n","pred_sub = modelo1.predict(X_test)\n","\n","# Predicción utilizando SMOTE\n","pred_smote = modelo2.predict(X_test)\n","\n","# Predicción utilizando MSMOTE\n","pred_msmote = modelo3.predict(X_test)"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fk_GEUakfg3i"},"source":["## Ejercicio 4\n","\n","**Obtenga e imprima la matriz de confusión para cada modelo, así como los informes de clasificación.**"]},{"cell_type":"code","metadata":{"id":"C3lk_fHYf5Mv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620690554805,"user_tz":300,"elapsed":574,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}},"outputId":"7b9baa25-2ae8-4af0-b349-36ad5cc7e3df"},"source":["# Escriba su código a continuación y presione Shift + Enter para ejecutar\n","\n","from sklearn.metrics import classification_report\n","\n","# Obtenemos la matriz de confusión a partir de los resultados obtenidos\n","confusionMatrix1 = confusion_matrix(y_test, pred_sub)\n","confusionMatrix2 = confusion_matrix(y_test, pred_smote)\n","confusionMatrix3 = confusion_matrix(y_test, pred_msmote)\n","\n","print(\"---RESULTADOS MODELO 1---\")\n","print(confusionMatrix1)\n","reporte1 = classification_report(y_test, pred_sub)\n","print(reporte1)\n","\n","print(\"---RESULTADOS MODELO 2---\")\n","print(confusionMatrix2)\n","reporte2 = classification_report(y_test, pred_smote)\n","print(reporte2)\n","\n","print(\"---RESULTADOS MODELO 3---\")\n","print(confusionMatrix3)\n","reporte3 = classification_report(y_test, pred_msmote)\n","print(reporte3)\n"],"execution_count":44,"outputs":[{"output_type":"stream","text":["---RESULTADOS MODELO 1---\n","[[1032  251]\n"," [  57  160]]\n","              precision    recall  f1-score   support\n","\n","          No       0.95      0.80      0.87      1283\n","         Yes       0.39      0.74      0.51       217\n","\n","    accuracy                           0.79      1500\n","   macro avg       0.67      0.77      0.69      1500\n","weighted avg       0.87      0.79      0.82      1500\n","\n","---RESULTADOS MODELO 2---\n","[[1008  275]\n"," [  55  162]]\n","              precision    recall  f1-score   support\n","\n","          No       0.95      0.79      0.86      1283\n","         Yes       0.37      0.75      0.50       217\n","\n","    accuracy                           0.78      1500\n","   macro avg       0.66      0.77      0.68      1500\n","weighted avg       0.86      0.78      0.81      1500\n","\n","---RESULTADOS MODELO 3---\n","[[1042  241]\n"," [  55  162]]\n","              precision    recall  f1-score   support\n","\n","          No       0.95      0.81      0.88      1283\n","         Yes       0.40      0.75      0.52       217\n","\n","    accuracy                           0.80      1500\n","   macro avg       0.68      0.78      0.70      1500\n","weighted avg       0.87      0.80      0.82      1500\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3BHYBAOWkSop"},"source":["**SOLUCIÓN DEL EJERCICIO:**"]},{"cell_type":"markdown","metadata":{"id":"cJlGlTDjkWEw"},"source":["Haga doble clic **aquí** para ver la solución del Ejercicio 3. \n","\n","<!-- La respuesta es la siguiente:\n","\n","from sklearn.metrics import classification_report\n","\n","# Obtenemos la matriz de confusión a partir de los resultados obtenidos\n","confusionMatrix1 = confusion_matrix(y_test, pred_sub)\n","confusionMatrix2 = confusion_matrix(y_test, pred_smote)\n","confusionMatrix3 = confusion_matrix(y_test, pred_msmote)\n","\n","print(\"---RESULTADOS MODELO 1---\")\n","print(confusionMatrix1)\n","reporte1 = classification_report(y_test, pred_sub)\n","print(reporte1)\n","\n","print(\"---RESULTADOS MODELO 2---\")\n","print(confusionMatrix2)\n","reporte2 = classification_report(y_test, pred_smote)\n","print(reporte2)\n","\n","print(\"---RESULTADOS MODELO 3---\")\n","print(confusionMatrix3)\n","reporte3 = classification_report(y_test, pred_msmote)\n","print(reporte3)\n","\n","-->"]},{"cell_type":"markdown","metadata":{"id":"BpiOSz4e6eiJ"},"source":["A partir del informe de clasificación, podemos ver que MSMOTE tiene la mejor precisión, 80%, en comparación con las técnicas SMOTE y de submuestreo, que alcanzan el 78% y el 79%, respectivamente. Sin embargo, sabemos que es importante tener en cuenta los valores de *Recall*, especialmente de la clase minoritaria.\n","<br><br>\n","Vemos que SMOTE y MSMOTE tienen el valor más alto (76%) para la métrica *Recall*. Esto significa que estos modelos han identificado correctamente al 76% de los clientes que probablemente abandonen el operador. El submuestreo aleatorio tiene un valor de *Recall* más bajo de 74%. De esta manera, tenemos una situación en la que MSMOTE tiene mejores resultados. \n","<br><br>\n","También es importante mirar los puntajes de **f1**, que es un puntaje ponderado entre la *Precisión de clase* y *Recall*. De todos los puntajes f1, vemos que MSMOTE tiene el puntaje f1 más alto del 52%, con SMOTE 50% y con submuestreo aleatorio 51%. Por lo tanto, **podemos seleccionar MSMOTE como la mejor técnica para equilibrar en este contexto.\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"PVhTRs0jr1px","executionInfo":{"status":"ok","timestamp":1620690559346,"user_tz":300,"elapsed":479,"user":{"displayName":"Lvmen Innovations","photoUrl":"","userId":"00377461434728345638"}}},"source":[""],"execution_count":44,"outputs":[]}]}